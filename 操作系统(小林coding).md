# 操作系统(小林coding)

## 一、硬件结构

### 1.1 CPU是如何执行程序的？

**冯诺依曼模型**

![image-20230516115743671](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516115743671.png)

定义了计算机基本结构

1. 中央处理器（CPU）
2. 内存
3. 输入设备
4. 输出设备
5. 总线



**内存**

程序和数据都是存储在内存的，存储的区域是线性的。

数据存储的单位是一个二进制位（bit），即0或1。最小的存储单位是字节（byte），1byte=8bit

内存的地址从0开始编号，然后递增排列，结构类似数组，因此内存读写任何一个数据的速度都是一样的



**中央处理器**（CPU）

32位和64位CPU最主要的区别在于一次能计算多少字节数据：

- 32位CPU一次可以计算4个字节
- 64位PU一次可以计算8个字节

32位和64位通常称为CPU的位宽

CPU这样的设计的原因是为了能计算更大的值，如果是8位CPU，一次只能计算1个字节，即0~255的范围，这样就无法一完成计算10000*500，于是为了能够一次计算大数的运算，CPU需要支持多个byte一起计算，因此CPU位宽越大，可以计算的数值也就越大。



CPU内部还有一些组件，常见的有寄存器、控制单元和逻辑运算单元等。

- 控制单元：负责控制CPU工作
- 逻辑运算单元：负责计算
- 寄存器：有多种类型，每种寄存器的功能不一样。主要储存计算时的数据，寄存器就在CPU里，且紧挨着控制单元和逻辑运算单元，计算速度更快。
  1. 通用寄存器：用来存放需要进行运算的数据
  2. 程序计数器：用来存储CPU要执行的下一条指令**所在的内存地址**，此时指令还在内存中
  3. 指令寄存器：用来存放程序计数器指向的指令，即指令本身，指令被执行完之前都存储在这里



***为什么有程序计数器存放下一条指令的内存地址，还需要指令寄存器呢？***

程序计数器和指令寄存器都是计算机中重要的寄存器之一，但是它们的作用是不同的。程序计数器用于存放下一条指令在内存中的地址，而指令寄存器则是用于存放当前正在执行的指令。

当计算机需要执行指令时，程序计数器会把下一条指令的地址取出来，然后将其存放到指令寄存器中，执行该指令后指令寄存器会自动移动到下一条指令的内存地址。这样计算机就能顺序执行程序中的指令了。

另外，指令寄存器还可以用于存放预取出的指令，这样可以提高指令的执行效率。当执行完当前指令后，指令寄存器可以直接取出预取出的指令执行，而不需要重新从内存中取出下一条指令的地址，从而节省了时间。



**总线**

总线用于CPU和内存以及其他设备之间的通信，可分为3种

- 地址总线：用于指定CPU将要操作的内存地址
- 数据总线：用于读写内存的数据
- 控制总线：用于发送和接收信号，比如中断、设备复位等信号，

当CPU要读写内存数据时，一般通过两个总线：

- 

- 首先通过地址总线指定内存地址
- 再通过数据总线来传输数据



**输入、输出设备**

输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。期间，如果输入设备是键盘，按下按键是需要和CPU进行交互的，此时就需要用到控制总线了。



**线路位宽与CPU位宽**

数据通过线路电压的变化来传输的，低电压表示0，高电压表示1

一位一位的传输方式称为串行，下一个bit必须等待上一个bit传输完成后才能进行传输。如果想一次传输多位数据，只需要增加线路即可，此时数据可以并行传输。

为了避免低效率的串行传输的方式，线路的位宽最好一次就能访问到所有的内存地址。CPU要想操作内存地址就需要总线，如果总线只有一条，那每次只能表示0或1这两种情况，所以CPU一次只能操作两个内存地址了，如果CPU要想操作4G的内存，就需要32条地址总线，因为log2(4G)=32

CPU的位宽最好不要小于线路位宽，32位CPU一次最多只能操作32位宽的地址总线和数据总线

如果计算的数额不超过2^32的情况下，32位和64位CPU之间的处理速度没什么区别

32位CPU最大只能操作4GB内存，就算有8GB内存条也没用，因为寻址不到。而64位CPU的理论最大寻址空间2^64



**程序执行的基本过程**

程序实际上是一条一条指令，程序的运行过程实际上就是一条一条执行指令，负责执行指令的就是CPU了

![](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516172737104.png)

1. CPU获取程序计数器的值，该值是指令的内存地址，然后CPU的控制单元通过操作地址总线指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过数据总线将指令数据传给CPU，CPU接收到内存传来的地址后，将这个指令数据存入到指令寄存器
2. CPU分析指令寄存器中的指令，确定之类的类型和参数，如果是计算类型的指令，就把指令交给逻辑运算单元运算；如果是存储类型的指令，则交给控制单元执行
3. CPU执行完指令后，程序计数器的值自增，表示指向下一条指令。自增的大小由CPU的位宽决定，比如32位的CPU，指令是4个字节，需要4个内存地址存放，因此程序计数器的值会增加4

总结：一个从程序执行的时候，CPU会根据程序计数器的内存地址，从内存里把需要执行的指令读取到指令寄存器里面指向。然后根据指令长度自增，即自增到下一个指令内存地址，然后又开始循环反复



**a=1+2的执行具体过程**

CPU不认识a=1+2这个字符串，这个字符串只是方便我们程序员认识。要想将这段程序跑起来，还需要把整个程序编译成汇编代码。

针对汇编代码，还需要把汇编代码翻译成机器码，即由0和1组成的机器语言。

程序编译过程中，编译器通过分析代码，发现1和2是数据，于是程序运行时，内存会有个专门的区域来存放这些数据，这个区域就是**数据段**，注意，数据和指令是分开区域存放的，存放指令区域的地方叫做**正文段**，如下图

![image-20230516175213486](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516175213486.png)

![image-20230516175315117](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516175315117.png)

注意，以上是编译器干的事

由于是在32位CPU执行的，因此一条指令是占32位大小，所以每条指令间隔4个字节

而数据的大小是根据程序中指定的变量类型，比如int类型的数据占4个字节，char类型的数据占1个字节



**指令**

上图中的指令内容实际上是一串二进制数字的机器码，简易的汇编代码实际上只是方便我们理解

不同的CPU有不同的指令集，也就对应着不同的汇编语言和不同的机器码

![image-20230516175730079](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516175730079.png)

- R指令：用在算数和逻辑操作，里面有读取和写入数据的寄存器地址。如果是逻辑位移操作，后面还有位移操作的位移量，而最后的功能码则是再前面的操作码不够时，扩展操作码；来表示对应的具体指令
- I指令：用在数据传输、条件分支等。这个类型的指令，就没有了位移量和操作码，也没有了第三个寄存器，而是把这三部分直接合并成了一个地址值或一个常数
- J指令：用在跳转，高6位之外的26位都是一个跳转的目标地址

![image-20230516180206781](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516180206781.png)

编译器在编译程序时会构造指令，这个过程叫做指令的编码。CPU执行程序时，就会解析指令，这个过程叫做指令的解码。

现代大多数CPU都使用流水线的方式来执行指令，所谓的流水线实际上就是把一个任务拆分成多个小任务，于是一条指令通常分为4个阶段，称为4级流水线，如下图：
![image-20230516180526634](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516180526634.png)

1. Fetch：CPU通过程序计数器读取对应内存地址的指令
2. Decode：CPU对指令进行解码
3. Execute：CPU执行指令
4. Store：CPU将计算结果存回寄存器或者将寄存器的值存入内存

这4个阶段，称为指令周期（Instruction Cycle），CPU的工作就是一个周期接着一个周期，周而复始

实际上，不同阶段其实是由计算机中不同组件完成的

![image-20230516180919407](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516180919407.png)



**指令的类型**

![image-20230516181111705](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516181111705.png)



**指令的执行速度**

![image-20230516181343630](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516181343630.png)

假设CPU的主频是2.4GHz，意味着1秒钟会产生2.4G次的脉冲信号，则时钟周期时间是(1/2.4G)s

提升CPU执行效率可以从两方面入手：

1. 降低时钟周期时间，即提高CPU主频，但今非昔比，摩尔定律早已失效，CPU主频很难再做到翻倍成长
2. 降低CPU时钟周期数

CPU时钟周期数可以拆解成 指令数*每条指令的平均时钟周期数（Cycles Per Instruction，简称CPI）

![image-20230516181942446](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516181942446.png)

![image-20230516182130394](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516182130394.png)



**总结**

![image-20230516183411326](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230516183411326.png)



### 1.2 存储器金字塔

内存和硬盘都属于计算机的存储设备，断电后内存的数据是会丢失的，而硬盘不会，因为硬盘是持久化存储设备，同时也是一个I/O设备

CPU内部也有存储数据的组件，比如寄存器、CPU的L1/L2/L3 Cache，只不过存储的数据非常小，但又因为接近CPU核心，所以访问速度很快，比硬盘快好几个数量级



**存储器的层次结构**

1. CPU内部

   - CPU：大脑

   - CPU中的寄存器：大脑正在思考的东西，处理速度最快，但是能存储的数据也是最少的

   - CPU Cache：大脑中的记忆

     ——L1 Cache：数据存储和指令存储，L1距离CPU最近，所以它比L2、L3的读写速度都更快、存储空间更小

     ——L2/L3 Cache：大脑中的长期记忆

     寄存器和CPU Cache都在CPU内部，跟CPU距离近，因此读写速度都快，但是内存小

2. CPU外部

   - 内存：书桌上的书，虽然一伸手就可以拿到，但是读写速度远慢于寄存器
   - 硬盘：图书馆书架上的书，能存储的数据十分大，但是读写速度比内存差好几个数量级

   ![image-20230518230811525](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230518230811525.png)

从图书馆书架取书，把书放到桌子上，再阅读书，大脑记忆知识点，然后经过大脑思考。这一过程相当于从硬盘加载到内存，再从内存加载到CPU的寄存器和Cache中，然后再通过CPU进行处理和计算

对于存储器，速度越快 -> 能耗越高 -> 材料成本越贵，所以速度快的存储器容量都比较小

存储器可以分为以下几个级别：

- 寄存器
- CPU Cache：
  1. L1-Cache
  2. L2-Cache
  3. L3-Cache
- 内存
- SSD/HDD硬盘



**寄存器**

最靠近CPU控制单元和逻辑计算单元的存储器

- 32位CPU中大多数寄存器可以存储4个字节
- 64位CPU中大多数寄存器可以存储8个字节

寄存器的访问速度非常快，一般要求在半个CPU时钟周期内完成读写，CPU时钟周期跟CPU主频息息相关，比如2GHz主频的CPU的时钟周期就是1/2G，也就是0.5ns

CPU处理一条指令的时候，除了读写寄存器，还需要解码指令、控制指令执行和计算。如果寄存器的速度太慢，则会拉长指令的处理周期，从而给用户感觉电脑"很慢"



**CPU Cache**

CPU Cache用的是一种叫SRAM(Static Random-Access Memory，静态随机存储器)的芯片

SRAM之所以叫静态存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了

在SRAM中，一个bit的数据，通常需要6晶体管，所以SRAM存储密度不高，同样的物理空间下，能存储的数据有限，不过因为SRAM电路简单，所以访问速度非常快

![image-20230519103257378](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230519103257378.png)



**L1高速缓存**

L1高速缓存的访问速度几乎和寄存器一样快，通常只需要2~4个时钟周期，大小在几十KB到几百KB不等

每个CPU核心都有一块属于自己的L1高速缓存，指令和数据在L1是分开存放的，所以L1高速缓存通常分成指令缓存和数据缓存



**L2高速缓存**

L2高速缓存同样存在于每个CPU核心，但离CPU核心的位置比L1更远，但大小比L1大，CPU型号不同大小也不同，通常在几百KB到几MB不等，访问速度更慢，在10~20个时钟周期



**L3高速缓存**

L3高速缓存通常是多个CPU核心共用，位置比L2高速缓存距离CPU核心更远，但大小更大，通常在几MB到几十MB不等，访问速度在20~60个时钟周期



**内存**

内存使用DRAM(Dynamic Random Access Memory，动态随机存取存储器)的芯片

相比SRAM，DRAM的密度更高，功耗更低，有更大的容量，而且造价比SRAM芯片便宜很多

DRAM存储一个bit数据，只需要一个晶体管和一个电容，但是因为数据会被存储在电容里，电容会不断漏电，所以需要定时刷新电容，才能保证数据不会丢失，这就是DRAM被称为动态存储器的原因，只有不断刷新，数据才不会丢失，才能够存储起来

DRAM的数据访问电路和刷新电路都比SRAM更复杂，所以访问速度会更慢，内存速度大概在200~300个时钟周期



**SSD/HDD硬盘**

SSD（Solid-state disk），固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还在，而内存、寄存器、高速缓存断电后数据都会丢失。内存读写的速度比SSD快10~1000倍

还有一种传统硬盘，即机械硬盘（Hard Disk Drive，HDD），通过物理读写的方式来访问数据，因此访问速度非常慢，比内存慢10w倍左右

由于SSD价格接近机械硬盘，因此机械硬盘已经逐渐被SSD替代了



**存储器的层次关系**

CPU并不会直接和每一种存储器设备直接打交道，而是每一种存储器设备只和它相邻的存储器设备打交道

![image-20230519205756455](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230519205756455.png)

当CPU需要访问内存中的某个数据时，如果寄存器有这个数据，CPU直接从寄存器取数据即可，如果寄存器没有这个数据，CPU就会查询L1高速缓存，如果L1没有，则查询L2高速缓存，L2还是没有就查询L3高速缓存，L3依然没有的话，才去内存中取数据。（顿时理解了为什么传的是地址而不是其它了，因为地址是唯一的，不会出现歧义，而值可能有相等的两个值出现的情况）所以，存储层次结构也形成了缓存的体系



**存储器之间的实际价格和性能差距**

![image-20230519235919850](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230519235919850.png)



**总结**

不同的存储器之间性能差距很大，构造存储器分级很有意义，分级的目的是要构造缓存体系



### 1.3 如何写出让CPU跑得更快的代码？

**CPU Cache有多快？**

CPU和内存的访问速度的增长速率不匹配，导致CPU与内存的访问速度相差200~300多倍，意味着内存已经不满足CPU的需求了。为了弥补CPU与内存二者之间的性能差异，就在CPU内部引入了CPU Cache，也称高速缓存

CPU Cache通常分为大小不等的三级缓存，分别是L1 Cache、L2 Cache和L3 Cache

L3 Cache比L1 Cache和L2 Cache大很多，这是因为L1 Cache和L2 Cache都是每个CPU核心独有的，而L3 Cache是多个CPU核心共享的

![image-20230520083808622](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230520083808622.png)



**CPU Cache的数据结构和读取过程是什么样的？**

CPU Cache的数据是从内存中读取过来的，以一小块一小块读取数据的，而不是按照单个数据元素读取数据。在CPU Cache中，这样一小块一小块的数据，称为Cache Line（缓存块）

比如，有一个int array[100]的数组，载入array[0]时，由于数组元素大小在内存只占4字节，不足64字节，CPU就会顺序加载数组元素到array[15]，意味着array[0]~array[15]数组元素都会被缓存在CPU Cache中，因此当下次访问这些数组元素时，会直接从CPU Cache读取，而不需要再从内存中读取，大大提高了CPU读取数据的性能。

事实上，CPU读取数据时，无论数据是否存放到Cache中，CPU都是先访问Cache，只有当Cache中找不到数据时，才回去访问内存，并把内存中的数据读入到Cache中，CPU再从CPU Cache读取数据

![image-20230522114337651](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230522114337651.png)

这样的访问机制，和使用 内存作为硬盘的缓存 的逻辑是一样的，如果内存有缓存的数据，则直接返回，否则要访问龟速般的硬盘

CPU访问内存数据时，是一小块一小块数据读取的，具体大小取决于coherency_line_size的值，一般是64字节。在内存中，这块数据称为内存块（Block），读取时我们需要拿到数据所在内存块的地址。

**直接映射Cache（Direct Mapped Cache）**

把内存块的地址始终 映射 在一个CPU Line（缓存块）的地址，至于映射关系实现方式，则是使用 取模运算，取模运算的结果就是内存块地址对应的CPU Line（缓存块）的地址

![image-20230522114953280](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230522114953280.png)

为了区别不同的内存块，在对应的CPU Line中会存储一个组标记（Tag），记录当前CPU Line中存储的数据对应的内存块，可以使用组标记来区分不同组但映射到同一块CPU Line的内存块。

除了组标记信息外，CPU Line还有两个信息：

1. 从内存加载过来的实际存放数据（Data）
2. 有效位（Valid bit），它是用标记对应的CPU Line中的数据是否是有效的，如果有效位是0，无论CPU Line中是否有数据，CPU都会直接访问内存，重新加载数据。

CPU在从CPU Cache读取数据时，并不是读取CPU Line中的整个数据块，而是读取CPU所需要的一个数据片段（Block），这样的数据统称为一个字（Word），即一个特。在对应的CPU Line中数据块中找到所需的字需要一个偏移量（Offset）

因此，一个内存的访问地址，包括组标记、CPU Line索引、偏移量，对于CPU Cache里的数据结构，则是由索引+有效位+组标记+数据块组成

![image-20230522233014701](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230522233014701.png)

如果内存中的数据已经在CPU Cache中，CPU访问一个内存地址的时候，会经历以下4个步骤：

1. 根据内存地址中索引信息，计算在CPU Cache中的索引，也就是找出对应的CPU Line的地址
2. 找到对应CPU Line后，判断CPU Line中的有效位，确认CPU LIne中数据是否有效，如果无效，CPU直接访问内存，并重新加载数据，如果数据有效，则往下执行
3. 对比内存地址中组标记和CPU Line中的组标记，确认CPU Line中的数据是我们要访问的内存数据，如果不是的话，CPU就会直接访问内存，并重新加载数据，如果是的话，则往下执行
4. 根据内存地址中偏移量信息，从CPU Line的数据块中，读取对应的字

其他通过内存地址找到CPU Cache中数据的策略：

- 全相连Cache（Fully Associative Cache）
- 组相连Cache（Set Associative Cache）



**如何写出让CPU跑得更快的代码？**

CPU访问内存的速度比访问CPU Cache的速度慢很多。所以如果 CPU  所要操作的数据在 CPU Cache 中的话，这样将会带来很⼤的性能提升。访问的数据在 CPU  Cache 中的话，意味着缓存命中，缓存命中率越⾼的话，代码的性能就会越好，CPU 也就跑 的越快。 于是，「如何写出让 CPU 跑得更快的代码？」这个问题，可以改成「如何写出 CPU 缓存命 中率⾼的代码？」。

L1 Cache通常分为数据缓存和指令缓存，因为CPu会分别处理数据和指令，比如 1+1=2 这个运算，+ 就是指令，会被放在「指令缓存」中，而输⼊数 字 1 则会被放在「数据缓存」里。

因此，要分开看 数据缓存 和 指令缓存 的缓存命中率

eg.

一行一行遍历二维数组的速度快于一列一列遍历二维数组，是因为二维数组所占用的内存是连续的，且是按行顺序来保存的，局部性原理。

CPU具体会一次从内存中加载多少元素到CPU Cache和CPU Cache Line有关，表示CPU Cache一次性能加载数据的大小（Word）。

因此，遇到遍历数组的问题，按照内存布局顺序访问访问，可以有效利用CPU Cache带来的好处，提高代码性能



**如何提高指令缓存的命中率？**

eg.

```cpp
//有一个元素为0到99之间随机数字组成的一维数组
int array[N];
for(int i=0;i<N;i++){
    array[i]=rand()%100;
}

//接下来，对这个数组做两个操作
//操作一：数组遍历
for(i=0;i<N;i++){
    if(array[i]<50){
        array[i]=0;
    }
}

//操作二：排序
sort(array,array+N);
```

问题：先遍历再排序快，还是先排序再遍历快

先了解CPU的分支预测期，对于if条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是if还是else中的指令。那么，如果分支预测可以预测到接下来要执行if里的指令还是else指令的话，就可以 提前 把这些指令放在缓存中，这样CPU可以直接从Cache读取到指令，于是执行速度就会很快

当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是有序时，分支预测会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。

因此先排序再遍历速度会快很多，因为排序后，数字是从小到大的，前几次循环命中if<50的次数会比较多，于是分支预测就会缓存if里的array[i]=0指令到Cache中，后序CPU执行该指令就只需要从Cache读取即可

如果你肯定代码中if中表达式判断为true的概率比较高，可以使用显示分支预测工具，比如在C/C++语言中编译器提供了likely和unlikely这两种宏，可以用likely宏把if里的表达式包裹起来，反之用unlikely宏

```cpp
#define likely(x)__builtin_expect(!!(x),1)
#define unlikely(x)__builtin_expect(!!(x),0)

if(likely(a==1)){
    //do something...
}else{
    //do something...
}
```

实际上，CPU自身的动态分支预测已经比较准了，只用当非常确信CPU预测的不准，且能够知道实际的概率情况时，才建议使用这两种宏。



**如何提升多核CPU的缓存命中率？**

在单核CPU，虽然只能执行一个进程，但是操作系统给每个进程分配了一个时间片，时间片用完了，就调度下一个进程，于是各个进程就按时间片交替地占用CPU，从宏观上看起来各个进程同时在执行

而现代CPU都是多核心的，进程可能在不同CPU核心来回切换执行，这对CPU Cache不是有利的，虽然L3 Cache事多核心之间共享的，但是L1和L2 Cache是每个核心独有的，如果一个进程在不同核心来回切换，各个核心呃缓存命中率会受到影响，相反如果进程都在同一个核心上执行，其数据的L1和L2 Cache的缓存命中率可以得到有效提高，缓存命中率高意味着CPU可以减少访问内存的频率

当有多个同时执行 计算密集型 的线程，为了防止因切换到不同的核心，而导致缓存命中率下降的问题，可以把线程绑定在某一个CPU核心上，性能得到非常可观的提升。



### 1.4 CPU缓存一致性

**CPU Cache的数据写入**

CPU Cache的结构：CPU Cache是由很多个Cache Line组成的，CPU Line是CPU从内存读取数据的基本单位，而CPU Line是由各种标志（Tag）+数据块（Data Block）组成

数据不光只有读操作，还有写操作，如果数据写入Cache之后，内存与Cache相对应的数据将会不同，这种情况下Cache和内存数据都不一致了，于是我们肯定需要把Cache中的数据同步到内存中。

两种写入数据的方法：

- 写直达（Write Through）
- 写回（Write Back）



**写直达**

保存内存与Cache一致性最简单的方式是，把数据同时写入内存和Cache中，这种方法成为写直达（Write Through）

写入钱会先判断数据是否已经在CPU Cache里面：

- 如果数据已经在Cache里面，先将数据更新到Cache里面，再写入到内存里面
- 如果数据没有在Cache里面，就直接把数据更新到内存里面

缺点：无论数据在不在Cache里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，性能会受到很大影响



**写回**

在写回机制中，当发生写操作时，新的数据仅仅被写入Cache Block，只有当修改过的Cache Block被替换时才需要写到内存中，减少了数据写回内存的频率，提高系统的性能

具体步骤：

- 如果当发生写操作时，数据已经在CPU Cache里的话，则把数据更新到CPU Cache里，同时标记CPU Cache里的这个Cache Block为脏（Dirty）的，表示CPU Cache里面的这个Cache Block的数据和内存不一致，这种情况还不需要把数据写回到内存中
- 如果当发生写操作时，数据所对应的Cache Block存放的是 别的内存地址的数据 的话，就要检查这个Cache Block里的数据是否标记为Dirty，如果已被标记，需要先把这个Cache Block里的数据写回到内存，然后再把当前要写入的数据写入到这个Cache Block，同时标记为Dirty；如果Cache Block没有被标记为Dirty，直接将数据写入到Cache Block就行，再把这个Cache Block标记为Dirty即可，原Cache Block无需写回到内存中



**缓存一致性问题**

现在CPU都是多核的，由于L1/L2 Cache是多个核心各自独有的，那么会带来多核心的缓存一致性问题。

假设A号核心和B号核心同时运行两个线程，都操作共同变量i（初始值为0）

![image-20230603002933850](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230603002933850.png)

A核心执行i++语句，出于性能的考虑，使用写回策略，先把值为1的执行结果写入到L1/L2 Cache中，然后把L1/L2 Cache中对应的Block标记为脏的，但这个时候数据还没有同步到内存中。这时如果B核心尝试从内存中读取变量i的值，将会得到错误的值，因为正确的i值还未被写回到内存中。所谓缓存一致性问题就是A号核心和B号核心的缓存在这个时候是不一致的。

![image-20230603004340070](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230603004340070.png)

解决这一问题需要一种机制，来同步两个不同核心里面的缓存数据，要做到以下2点：

- 第一点，某个CPU核心里的Cache数据更新时，必须要传播到其他核心的Cache，这称为写传播(Write Propagation)

- 第二点，某个CPU核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这称为事物的串行化(Transaction Serialization)

  举例：

  假设有一个含有4个核心的CPU，这4个核心都操作共同变量i（初始值为0）。A号核心先把i值变为100，而此时同一时间B号核心先把i值变为200，这里两个修改都会传播到C和D号核心。

  ![image-20230603005034489](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230603005034489.png)

  问题来了，C号核心先收到了A号核心更新数据的事件，再收到B号核心更新数据的事件，因此C号核心看到的变量i是先变成100，后变成200。而如果D号核心接受到的事件是反过来的，则D号核心看到的是变量i先变成200，再变成100，虽然做到了写传播，但是各个Cache里面的数据仍然不一致。

  所以，我们需要保证C号核心和D号核心都能看到相同顺序的数据变化，比如i变量都是先变成100，再变成200

  要实现事物串形化需要做到以下2点：

  - CPU核心对于Cache中数据的操作，需要同步给其他CPU核心
  - 引入 锁 的概念，如果两个CPU核心里有相同数据的Cache，对于这个Cache数据的更新，只有拿到了 锁 ，才能进行对应的数据更新



**总线嗅探**

写传播的原则就是当某个CPU核心更新了Cache中的数据，要把该事件广播通知到其他核心。最常见的实现方式是总线嗅探（Bus Snooping）

当A号CPU核心修改了L1 Cache中变量i的值，通过总线把这个事件广播通知给其他所有核心，然后每个CPU核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的L1 Cache里面，如果B号CPU核心的L1 Cache中有该数据，那么也需要把该数据更新到自己的L1 Cache。

总线嗅探的方式很简单，CPU需要每时每刻监听总线上的⼀切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出⼀个⼴播事件，这⽆疑会加重总线的负载。另外，总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串形化。



**MESI协议**

- Modified：已修改
- Exclusive：独占
- Shared：共享
- Invalidated：已失效

这四个状态来标记Cache Line四个不同的状态

已修改对应着脏标记，代表该Cache Block上的数据已经被更新过，但是还没有写到内存里

已失效表示这个Cache Block里的数据已经失效了，不可以读取该状态的数据

独占和共享状态都代表Cache Block里的数据是干净的，即这个时候Cache Block里的数据和内存里面的数据是一致性的

独占和共享的差别在于，独占状态是，数据只存储在一个CPU核心的Cache里，而其他CPU核心的Cache没有该数据。这个时候如果要向独占Cache写数据，就可以直接自由地写入，而不需要通知其他CPU核心，因为只有这个Cache有这个数据，就不存在缓存一致性问题，于是就可以随便操作该数据。

另外，在独占状态下的数据，如果有其他核心从内存也读取了相同的数据到各自的Cache，那么这个时候，独占状态下的数据就会变成共享状态

共享状态代表着相同的数据在多个CPU核心里的Cache里都有，所以当我们要更新Cache里面的数据的时候，不能直接修改，而是要先向所有的其他CPU核心广播一个请求，要求先把其他核心的Cache中对应的Cache Line标记为无效状态，然后再更新当前Cache里面的数据

eg：

1. 当A号核CPU核心从内存中读取变量i的值，数据被缓存在A号CPU核心自己的Cache里面，此时其他CPU核心的Cache没有缓存该数据，于是标记Cache Line状态为独占，此时其Cache中的数据与内存是一致的
2. 然后B号CPU核心也从内存中读取了变量i的值，此时会发送消息给其他CPU核心，由于A号CPU核心已经缓存了该数据，所以会把数据返回给B号CPU核心，在这个时候，A和B核心缓存了相同的数据，Cache Line的状态就会变成共享，并且其Cache中的数据与内存也是一致的
3. 当A号CPU核心要修改Cache中i变量的值，发现数据对应的Cache Line的状态是共享状态，则要向所有其他CPU核心广播一个请求，要求先把其他核心的Cache中对应的Cache Line标记为无效状态，然后A号CPU核心才更新里面的数据，同时标记Cache Line为已修改状态，此时Cache中的数据就与内存不一致了
4. 如果A号CPU核心继续修改Cache中i变量的值，由于此时的Cache LIne是已修改状态，因此不需要给其他CPU核心发送消息，直接更新数据即可
5. 如果A号CPU核心的Cache对应的i变量对应的Cache要被替换，发送Cache Line状态是已修改状态，就会在替换前先把数据同步到内存中

所以，发现当Cache Line状态是已修改或者独占状态时，修改更新其数据不需要广播给其他CPU核心

![image-20230606170143573](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606170143573.png)



**总结**

CPU在读写数据：

- CPU读数据：都是在CPU Cache读写数据的，原因是Cache里CPU很近，读写性能相比内存高出很多。对于Cache里没有缓存CPU所需要的数据的情况，CPU则会从内存中读取数据，并将数据缓存到Cache里面，最后CPU再从Cache读取数据
- CPU写数据：写直达 或 写回 两种策略

缓存一致性：

1. 写传播
2. 事物的串行化

基于总线嗅探的MESI协议满足以上两点，保障了缓存一致性



### 1.5 CPU是如何执行任务的

**问题引入**

![image-20230606171032749](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606171032749.png)



**CPU如何读写数据的？**

> Cache伪共享是什么？

现在假设有一个双核心的CPU，这两个CPU核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分类是类型为long的变量A和B，这两个数据的地址在物理内存上是连续的，如果Cache LIne的大小是64字节，并且变量A在Cache Line的开头位置，那么这两个数据是位于同一个Cache Line中，又因为CPU Line是CPU从内存读取数据到Cache的单位，所以这两个数据会被同时读入到了两个CPU核心中各自的Cache中。

![image-20230606172039837](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606172039837.png)

如果两个不同核心的线程分别修改不同的数据，比如1号核心的线程只修改了变量A，或2号CPU核心的线程只修改了变量B，会发生什么？

**分析伪共享问题**

结合保证多核缓存一致的MESI协议，来说明整个过程。

1. 最开始变量A和B都还不在Cache里面，假设1号核心绑定了线程A，2号核心绑定了线程B，线程A只会读写变量A，线程B只会读写变量B

   ![image-20230606172338067](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606172338067.png)

2. 1号核心读取变量A，由于CPU从内存读取数据到Cache的单位是Cache Line，也正好是变了A和B的数据归属于同一个Cache Line，所以A和B的数据都会被加载到Cache，并将此Cache Line标记为独占状态

   ![image-20230606172618661](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606172618661.png)

3. 接着，2号核心开始从内存里读取变量B，同样也是读取Cache Line大小的数据到Cache中，此Cache Line中的数据也包含了变量A和B，此时1号和2号核心的Cache Line状态变为共享状态

   ![image-20230606173143393](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606173143393.png)

4. 1号核心需要修改变量A，发现此Cache Line的状态是共享状态，所以先需要通过总线发送消息给2号核心，通知2号核心把Cache中对应的Cache Line标记为已失效状态，然后1号核心对应的Cache Line状态变成已修改状态，并且修改变量A

   ![](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606173401364.png)

5. 之后，2号核心需要修改变量B，此时2号核心的Cache中对应的Cache Line是已失效状态，另外由于1号核心的Cache也有此相同的数据，且状态为已修改状态，所以要先把1号核心的Cache对应的Cache Line写回内存，然后2号核心再从内存读取Cache Line大小的数据到Cache中，最后把变量B修改到2号核心的Cache中，并将状态标记为已修改状态

   ![image-20230606173650430](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606173650430.png)

Cache并没有起到缓存的效果，虽然变量A和B之间其实没有任何的关系，但是因为同时归属于一个 Cache Line，这个Cache Line中的任意数据被修改后，都会相互影响，从而出现4和5这两个步骤

因此，这种因为多个线程同时读写同一个Cache Line的不同变量时，而导致CPU Cache失效的现象称为伪共享（False Sharing)



**避免伪共享的方法**

因此，对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在用一个Cache Line中，否则就会出现伪共享问题

![image-20230606175708574](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606175708574.png)

从上面的宏定义可以看到：

- 如果在多核（MP）系统里，该宏定义是__cacheline_aligned，也就是Cache Line的大小
- 如果在单核系统里，该宏定义是空的

因此针对在同一个Cache Line中的共享的数据，如果在多核之间竞争比较严重，为了防止伪共享现象的发生，可以采用上面的宏定义使得变量在Cache Line里是对齐的

```cpp
假设有以下结构体
struct test{
    int a;
    int b;
};

结构体里的两个成员变量a和b在物理内存地址上是连续的，于是它们可能会位于同一个Cache Line中，所以，为了防止前面提到的Cache伪共享问题，我们可以使用上面的宏定义，将b的地址设置为Cache Line对齐地址，如下：
struct test{
    int a;
    int b __cacheline_aligned_in_smp;
};

这样a和b变量就不会在同一个Cache Line中了
```

![image-20230606193147880](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606193147880.png)

所以，避免Cache伪共享实际上是用空间换时间的思想

另一个应用层面的规避方案，有一个Java并发框架Discruptor使用 字节填充+继承 的方式，来避免伪共享问题

![image-20230606193314239](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606193314239.png)

RingBufferPad类里7个long类型的名字看起来很奇怪，但事实上，它们虽然看起来毫无作用，但是对性能的提升起到了至关重要的作用

CPU Cache从内存读取数据的单位是CPU Line，一般64位CPU的CPU Line的大小是64字节，一个long类型的数据是8个字节，所以CPU一下会加载8个long类型的数据

根据JVM对象继承关系中父类成员和子类成员，内存地址是连续排列布局的，因此RingBufferPad中的7个long类型数据作为Cache Line前置填充，而RingBuffer中的7个long类型数据则作为Cache Line后置填充，这14个long变量没有任何实际用途，更不会对它们进行读写操作

![image-20230606193705569](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606193705569.png)

另外，RingBufferFelds里面定义的这些变量都是final修饰的，意味着第一次加载之后不会再修改，又由于前后各填充了7个不会被读写的long类型变量，所以无论怎么加载Cache Line，这整个Cache Line里都没有会发生更新操作的数据，于是只要数据被频繁地读取访问，就自然没有数据被换出Cache的可能，也因此不会产生伪共享问题



**CPU如何选择线程的？**

在Linux内核中，进程和线程都是用tark_struct结构体表示的，区别在于线程的tark_struct结构体里部分资源是共享了进程已创建的资源，比如内存地址空间，代码段、文件描述符等， 所以Linux中的线程也被称为轻量级线程，因为线程的tart_struct相比进程的tatk_struct承载的资源比较少

一般来说，没有创建线程的进程，是只有单个执行流，它被称为是主线程。如果想让进程处理更多事情，可以创建多个线程分别去处理，但不管怎么样，它们对应到内核里都是tark_struct

![image-20230606194224186](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606194224186.png)

所以，Linux内核里的调度器，调度的对象就是tark_struct，接下来就把这个数据结构统称为任务

在Linux系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：

- 实时任务：对系统的响应时间要求很高，也就是要尽可能快的执行实时任务，优先级在0~99范围内的就算实时任务
- 普通任务：响应时间没有很高的要求，优先级在100~139范围内的都是普通任务级别



**调度类**

由于任务有优先级之分，Linux系统为了保障高优先级的任务能够尽可能早的被执行，于是分为了这几种调度类，如下图：

![image-20230606194946921](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606194946921.png)

![image-20230606195037417](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606195037417.png)



**完全公平调度（Completely Fair Scheduling）**

这个算法的理念是想让分配给每个任务的CPU时间是一样的，于是它为每个任务安排一个虚拟运行时间vruntime，如果一个任务在运行，其运行的越久，该任务的vruntime自然就会越大，而没有被运行的任务，vruntime是不会变化的

在CFS算法调度的时候，会优先选择vruntime少的任务，以保证每个任务的公平性，同时计算vruntime的同时还要考虑普通任务的权重值，并不是优先级的值，内核中会有一个nice级别与权重值的转换表，nice级别越低的权重值就越大

![image-20230606195440064](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606195440064.png)

把NICE_0_LOAD当作一个常量，通过计算，高权重任务的vruntime比低权重的vruntime少，由于是CFS调度，所以会优先选择vruntime少的任务进行调度，所以高权重的任务就会被优先调度了，于是高权重的实际运行时间自然就多了



**CPU运行队列**

一个系统通常都会运行很多任务，多任务的数量基本都是远超CPU核心数量的，因此这时候就需要排队

事实上，每个CPU都有自己的运行队列，，用于描述在此CPU上所运行的所有进程，其队列包含三个运行队列，Deadline运行队列dl_rq、实时任务运行队列rt_rq和CFS运行队列csf_rq，其中cfs_rq是用红黑树来描述的，按vruntime大小来排序的，最左侧的叶子节点，就是下次会被调度的任务

![image-20230606195926346](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606195926346.png)

这几种调度类是有优先级的，优先级如下：Deadline>Realtime>Fair，这意味着Linux选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从dl_rq里选择任务，然后从rt_rq里选择任务，最后从csf_里选择任务。因此，实时任务总是会比普通任务优先被执行



**调整优先级**

如果启动任务时，没有特意指定优先级的话，默认呢情况下都是普通任务，普通任务的调度类是Fair，由CFS调度器来进行管理。CFS调度器的目的是实现任务运行的公平性，也就是保障每个人物的运行时间是差不多的

如果你想让某个普通任务有更多的执行时间，可以调整任务的nice值，从而让优先级高一些的任务执行更多时间。nice值能设置的范围是-20~19，值越低，表明优先级越高，因此，-20是最高优先级，19则是最低优先级，默认优先级是0

事实上，nice值并不是优先级，而是表示优先级的修正数据，它与优先级（priority）的关系是这样的：priority(new)=priority(old)+nice。内核中，priority的范围是0~139，值越低，优先级越高，其中前面的0~99范围是提供给实时任务使用的，而nice值是映射到100~139，这个范围是提供给普通任务用的，因此nice值调整的是普通任务的优先级

![image-20230606200701787](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606200701787.png)

![image-20230606200738769](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606200738769.png)

![image-20230606200749561](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606200749561.png)

nice值调整的是普通任务的优先级，所以不管怎么缩小nice值，任务永远都是普通任务，如果某些任务要求实时性比较高，那么可以考虑改变任务的优先级以及调度策略，使得它变成实时任务

![image-20230606200910961](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230606200910961.png)



### 1.6 软中断

**中断是什么？**

在计算机中，中断是系统用来响应硬件设备的请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。中断是一种异步的事件处理机制，可以提高系统的并发处理能力

操作系统收到了中断请求，会打断其他进程的运行，所以中断请求的响应程序，也就是中断处理程序，要尽可能快的执行完，这样可以减少对正常进程运行调度的影响。

而且，中断处理程序在响应中断时，可能还会 临时关闭中断，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就是说中断有可能会丢失，所以中断处理程序要短且快



**什么是软中断？**

Linux系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是上半部和下半部：

- 上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情
- 下半部用来延迟处理上半部未完成的工作，一般以 内核线程 的方式运行

也可以理解为：

- 上半部直接处理硬件请求，也就是硬中断，主要是负责耗时短的工作，特点是快速执行
- 下半部是由内核触发，也就是说软中断，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行

还有一个区别，硬中断（上半部）是会打断CPU正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个CPU都对应一个软中断内核线程，名字通常为 ksoftirqd/CPU编号

不过，软中断不只是包括硬件设备中断处理程序的下半部，一些内核自定义事件也属于软中断，比如内核调度等， RCU锁（内核里最常用的一种锁）等。



**系统里有哪些软中断？**

![image-20230611103732342](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611103732342.png)

![image-20230611103823318](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611103823318.png)

![image-20230611103836687](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611103836687.png)



**如何定位软中断CPU使用率过高的问题？**

![image-20230611103948403](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611103948403.png)

![image-20230611104014885](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611104014885.png)

![image-20230611104043991](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611104043991.png)



### 1.7 为什么0.1+0.2不等于0.3？

**引入：**

![image-20230611152043623](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611152043623.png)





**为什么负数要用补码表示？**

如果负数不是使用补码的方式表示，则在做基本对加减法运算时，还需要多一步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转为加法，因为加减法运算在计算机里十分常见，为了性能考虑，应当尽量简化该过程

利用补码的表示方式，对于负数的加减法操作，实际上是和正数的加减法操作一样的



**十进制小数与二进制的转换**

整数部分的转换是用**除2取整法**，而小数部分使用**乘2取整法**，将十进制中的小数部分乘以2作为二进制的一位，然后继续取小数部分乘以2作为下一位，直到不存在小数为止

![image-20230611152817368](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611152817368.png)

并非所有小数都可以转二进制表示

由于计算机的资源是有限的，所以没办法用二进制精确地表示0.1，只能用近似值来表示，就是在有限的精度情况下，最大化接近0.1的二进制数，于是就会造成精度缺失的情况



**计算机是怎么存小数的？**

计算机存储小数的采用的是浮点数，名字里的浮点表示小数点是可以浮动的

比如1000.101这个二进制数，可以表示成1.000101×2^3，类似于数学上的科学计数法

![image-20230611153340992](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153340992.png)

![image-20230611153359913](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153359913.png)

![image-20230611153433958](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153433958.png)

![image-20230611153550797](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153550797.png)



**0.1+0.2==0.3?**

![image-20230611153704996](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153704996.png)

![image-20230611153719375](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153719375.png)

![image-20230611153754054](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230611153754054.png)

这主要是因为有的小数无法可以用完整的二进制来表示，所以计算机里只能采用近似数的方式来保存，两个 近似数相加，得到的必然也是一个近似数



**总结**

负数采用补码的形式表达是为了统一和正数的加减法操作



## 二、操作系统结构

### 2.1 Linux内核 vs Windows内核

**内核**

内核作为应用连接硬件设备的桥梁，应用程序只需关心与内核交互，不用关心硬件的细节

![image-20230624214053359](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230624214053359.png)



现代操作系统，内核一般提供4个基本能力：

- 进程调度：管理进程、线程，决定哪个进程、线程使用CPU
- 内存管理：管理内存，决定内存的分配与回收
- 硬件通信：管理硬件设备，为进程与硬件设备之间提供通信能力
- 系统调用：提供系统调用，如果应用程序要运行更高权限的服务，就需要有系统调用，它是用户程序与操作系统之间的接口

内核具有很高的权限，可以控制CPU、内存、硬盘等硬件，而应用程序具有的权限很低，因此大多数操作系统吧内存分成了两个区域：

- 内核空间：该内存空间只有内核程序可以访问
- 用户空间：该内存空间专门给应用程序使用

用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，常说该程序在用户态执行，而当程序在内核空间时，程序则在内核态执行



应用程序如果需要进入内核空间，需要通过系统调用，以下是系统调用的过程：

![image-20230624215858936](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230624215858936.png)



**Linux的设计**

Linux内核设计理念：

- MultiTask：多任务
- SMP：对称多处理
- ELF：可执行文件链接格式
- Monolithic Kernel：宏内核

**MultiTask**

多任务意味着可以有多个任务同时执行，这里的同时可以是并发或并行

- 并发：对于单核CPU时，可以让每个任务执行一小段时间，时间到就切换到另一个任务，从宏观角度看，一段时间执行了多个任务
- 并行：对于多核CPU，多个任务可以同时被不同核心的CPU同时执行

**SMP**

对称多处理意味着每个CPU的地位是相等的，对资源的使用权限也是相同的，多个CPU共享同一个内存，每个CPU都可以访问完整的内存和硬件资源。这个特点决定了Linux操作系统不会有某个CPU单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个CPU上被执行

**ELF**

可执行文件链接格式是Linux中可执行文件的存储格式，格式如下：

![image-20230624225317963](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230624225317963.png)

ELF文件有两种索引，Program header table记录了运行时所需的短，Section header table记录了二进制文件中各个 段的首地址



ELF文件生成过程：

我们编写的代码，首先通过编译器编译成汇编代码，接着通过汇编器编程目标代码，也就是目标文件，最后通过链接器把多个目标文件以及调用的各种函数库链接起来，形成一个可执行文件，也就是ELF文件



ELF文件执行过程：

执行ELF文件时，会通过装载器把ELF文件装载到内存里，CPU读取内存中的指令和数据，于是程序就被执行起来了

**Monolithic Kernel**

Linux内核架构就是宏内核，意味着Linux的内核是一个完整的可执行程序，且拥有最高的权限

宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等都运行在内核态

Linux同时也实现了动态加载内核模块的功能，例如大部分设备驱动是以可加载模块的形式存在的，与内核其他模块解耦，让驱动开发和驱动加载更为方便、灵活。

![image-20230624230046619](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230624230046619.png)

与宏内核相反的是微内核，微内核架构的内核只保留最基本的能力，比如进程调度、虚拟机内存、中断等，把一些应用放到了用户空间，比如驱动程序、文件系统等。这样服务与服务之间是隔离的，单个服务出现故障或者完全攻击，也不会导致整个操作系统挂掉，提高了操作系统的稳定性和可靠性。



微内核内核功能少，可移植性高，相比宏内核有一点不好的地方在于，由于驱动程序不在内核中，而且驱动程序一般会频繁调用底层，于是驱动和硬件设备交互就需要频繁切换到内核态，带来性能损耗。



还有一种内核叫混合类型内核，他的架构类似微内核，内核里面会有一个最小版本的内核，然后其他模块在这个基础上搭建，实现时和宏内核类似，即把整个内核做成一个完整的程序，大部分服务都在内核中，相当于宏内核的方式包裹着一个微内核



**Windows设计**

当今Windows使用的内核叫Windows NT(New Technology)，结构如下：

![image-20230624230724068](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230624230724068.png)

Windows和Linux一样，同样支持MultiTask和SMP，但不同的是，Window的内核设计是混合型内核。

Windows的可执行文件的格式与Linux也不同，所以这两个系统的可执行文件是不可以在对方系统上运行的

Windows的可执行文件格式叫PE，称为可移植执行文件，扩展名通常是.exe、.dll、.sys。结构如下：

![image-20230624231112725](https://md-jomo.oss-cn-guangzhou.aliyuncs.com/IMG/image-20230624231112725.png)
